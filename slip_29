1.
from sklearn.decomposition import PCA
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Load dataset
iris = load_iris()
X = iris.data
y = iris.target

# Apply PCA (fit on training data only)
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

# Split data, train model
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)
model = LogisticRegression().fit(X_train, y_train)

# Evaluate
print(f"Accuracy: {accuracy_score(y_test, model.predict(X_test)):.2f}")

# Predict for new flower
new_flower = [[5.1, 3.5, 1.4, 0.2]]
pred = model.predict(pca.transform(new_flower))
print(f"Predicted class: {iris.target_names[pred][0]}")
------------------------------------------------------------------------------
2.
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score

# Sample dataset
df = pd.DataFrame({'EmployeeID':[1,2,3,4,5,6,7,8],
                   'Income':[40000,50000,60000,45000,70000,80000,75000,62000]})

# Scale data
X = StandardScaler().fit_transform(df[['Income']])

# Elbow method
inertia = [KMeans(n_clusters=k, random_state=42).fit(X).inertia_ for k in range(1,6)]
print("Inertia:", inertia)

# Silhouette scores
for k in range(2,5):
    labels = KMeans(n_clusters=k, random_state=42).fit_predict(X)
    print(f"k={k}, Silhouette={silhouette_score(X, labels):.2f}")

# Final clustering
df['Cluster'] = KMeans(n_clusters=3, random_state=42).fit_predict(X)
print(df)
-------------------------------------------------------------------------------
                                WITH CSV
2.
# Q2: K-means clustering on employee income dataset

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score

# -------------------------------
# Step 1: Read CSV
# -------------------------------
df = pd.read_csv("employees.csv")

# -------------------------------
# Step 2: Remove null values
# -------------------------------
df = df.dropna()

# -------------------------------
# Step 3: Select features for clustering
# -------------------------------
X = df[['Age', 'Experience', 'Income']]    # change if needed

# -------------------------------
# Step 4: Scale the data
# -------------------------------
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# -------------------------------
# Step 5: Elbow Method to find K
# -------------------------------
inertia = []

for k in range(2, 11):
    km = KMeans(n_clusters=k, random_state=42)
    km.fit(X_scaled)
    inertia.append(km.inertia_)

plt.plot(range(2, 11), inertia)
plt.xlabel("Number of Clusters (k)")
plt.ylabel("Inertia / Distortion")
plt.title("Elbow Method")
plt.show()

# -------------------------------
# Step 6: Silhouette Score to confirm K
# -------------------------------
for k in range(2, 11):
    km = KMeans(n_clusters=k, random_state=42)
    labels = km.fit_predict(X_scaled)
    sil = silhouette_score(X_scaled, labels)
    print(f"K = {k}, Silhouette Score = {sil}")

# -------------------------------
# Step 7: Apply K-Means with best K (example: k = 3)
# After checking elbow & silhouette, choose best K
# -------------------------------
best_k = 3
model = KMeans(n_clusters=best_k, random_state=42)
df['Cluster'] = model.fit_predict(X_scaled)

# -------------------------------
# Step 8: Print clustered data
# -------------------------------
print("\nClustered Data:")
print(df[['Age', 'Experience', 'Income', 'Cluster']])
