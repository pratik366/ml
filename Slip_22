1.
 # Import necessary libraries
 import pandas as pd
 from sklearn.model_selection import train_test_split
 from sklearn.linear_model import LinearRegression
 from sklearn.metrics import mean_squared_error
 
# Sample data (or load your data as df = pd.read_csv("your_dataset.csv"))
 data = {
    'size': [1500, 2000, 2500, None, 3000, 3500, 4000, None],
    'price': [300000, 400000, 500000, 450000, 600000, 700000, 800000, None]
 }
 df = pd.DataFrame(data)
 
# 1. Check and remove null values
 df = df.dropna()
 
# 2. Separate features and target variable
 X = df[['size']]   # Feature (independent variable)
 y = df['price']    # Target (dependent variable)
 
# 3. Split data into training and testing sets
 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
 
# 4. Initialize and train the Linear Regression model
 model = LinearRegression()
 model.fit(X_train, y_train)
 
# 5. Predict and evaluate the model
 y_pred = model.predict(X_test)
 mse = mean_squared_error(y_test, y_pred)
 print("Mean Squared Error:", mse)
 
# 6. Display model prediction for test data
 print("Predicted House Prices:", y_pred)
--------------------------------------------------------

2.
import pandas as pd
from mlxtend.frequent_patterns import apriori, association_rules
# Sample dataset (assuming a structure of one-hot encoded data)
data = {
'milk': [1, 1, 1, 0, 0, 1],
'bread': [1, 0, 1, 1, 1, 0],
'butter': [0, 1, 1, 1, 0, 1],
'beer': [1, 0, 0, 1, 1, 0]
}
df = pd.DataFrame(data)
# Apply Apriori algorithm with minimum support of 0.25
frequent_itemsets = apriori(df, min_support=0.25, use_colnames=True)
# Display results
print("Frequent Itemsets:")
print(frequent_itemsets)
# Generate association rules
rules = association_rules(frequent_itemsets, metric="lift", min_threshold=1)
print("\nAssociation Rules:")
print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])
----------------------------------------------------------------------------------------

                          WITH CSV

1.

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# -----------------------------
# Read CSV
# -----------------------------
df = pd.read_csv("house_price.csv")   # file name

# Feature & Target
X = df[['Area']]      # independent variable
y = df['Price']       # dependent variable

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# Model
model = LinearRegression()
model.fit(X_train, y_train)

# Prediction
y_pred = model.predict(X_test)

# Results
print("Predicted Prices:\n", y_pred)
print("Coefficient (slope):", model.coef_)
print("Intercept:", model.intercept_)
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
-----------------------------------------------------------------
2.

import pandas as pd
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori, association_rules

# -----------------------------
# Read CSV
# -----------------------------
df = pd.read_csv("groceries.csv", header=None)

# Convert each row to a list of items
transactions = df.values.tolist()

# -----------------------------
# Convert to One-Hot Encoding
# -----------------------------
te = TransactionEncoder()
te_data = te.fit(transactions).transform(transactions)
df_encoded = pd.DataFrame(te_data, columns=te.columns_)

# -----------------------------
# Apply Apriori Algorithm
# -----------------------------
frequent_items = apriori(df_encoded, min_support=0.25, use_colnames=True)

print("Frequent Itemsets:\n", frequent_items)

# -----------------------------
# Association Rules (optional)
# -----------------------------
rules = association_rules(frequent_items, metric="lift", min_threshold=1)
print("\nAssociation Rules:\n", rules)
